# Eigen Thingys

Tensors have gotten bandied about a lot in these Recipes. But what are they?

They are, among other things, [matrices](http://en.wikipedia.org/wiki/Matrix_%28mathematics%29), and, among other things matrices are linear maps that tell us what size and in which direction vectors will point after we have taken them from from a space we know about to a space we care about.4 Here, “take” is shorthand for “the [matrix product](http://en.wikipedia.org/wiki/Matrix_multiplication#Matrix_product_.28two_matrices.29) of linear map ___A___ and column vector _v_”

===
$$\mathbf{A}v = v'$$
===

That is, _v'_ usually points somewhere other than _v_, and has a different size or magnitude, because of its matrix multiplication by tensor ___A___, a linear map. ___A___ takes _v_ from the space we know about to a space we care about, where _v_ suddenly looks like _v'_. For example, if _v_ is ten meters long and points towards zero degrees azimuth (0°) in the space we know about, then ___A___ makes a new vector, _v'_ which is three meters long and points towards 192° azimuth in the space we care about.

| 1. | Spock: “Captain. Proceeding at Warp Factor 10 at zero degrees.” 10.0 ∡ 0.0° → left [ matrix{ 10.0 ## 0.0 } right ]
| 2. | left [ matrix{ -0.29344428 # 0.06237351 ## -0.06237351 # -0.29344428} right ] left [ matrix{10.00 ## 0.00} right ] = left [ matrix{ -2.9344428 ## -0.62373507 }right ]
| 3. | left [ matrix{ -2.9344428 ## -0.62373507 }right ] = sqrt{-2.9344428^2 + -0.62373507^2} ∡ arctan(-0.62373507, -2.9344428)
| 4. | Spock: “Captain: Now proceeding at Warp Factor 3 at 192 degrees.” 3.00 ∡ 192.0°

Often the space we know about and the space we care about is one and the same, so we call the linear map an operator. The salient aspect of this operator is that nearly every vector filtering through it will change length and direction.

If we make a study of this, however, we will discover that some vectors for some operators do not undergo a change in orientation. If there is any change in direction at all, it is a simple reversal, as if we had picked up the vector and turned it front-to-back so that it is still parallel with its old direction, and not lying transverse to it in any way. At most, whatever happens to this particular class of vectors is a change of size, and we can interpret a simple reversal of direction as a “negative” change of size.

| 1. | Linear Map B: left [ matrix{ 0.78 # 0.55 ## 0.55 # 1.32 }right]
| 2. | vector u: 1.0 ∡ 148.0734° = left [ matrix{ -0.84873 ## 0.52883} right ] ; vector v: 1.0 ∡ 238.0734° = left [ matrix{ -0.52883 ## -0.84873 } right ]
| 3. | {bold B}u = left [ matrix{ 0.78 # 0.55 ## 0.55 # 1.32 }right]left [ matrix{ -0.84873 ## 0.52883} right ] = left [ matrix{ -0.37115 ## 0.23126} right ] = 0.4373 times left [ matrix{ -0.84873 ## 0.52883} right ] = 0.4373 ∡ 148.0734°
| 4. | {bold B}v = left [ matrix{ 0.78 # 0.55 ## 0.55 # 1.32 }right] left [ matrix{ -0.52883 ## -0.84873 } right ] = left [ matrix{ -0.87929 ## -1.41118 } right ] = 1.6627 times left [ matrix{ -0.52883 ## -0.84873} right ] = 1.6627 ∡ 238.0734°

Here, vectors _u_ and _v_ did not change orientation. The linear map ___B___ simply rescaled them. We call such vectors “eigenvectors” for linear map ___B___, and the rescaling factors its “eigenvalues”. Here's a matrix equation describing the phenomenon:

===
$$ \mathbf{B}v = \lambda v $$
===

In this relation, the vector which merely undergoes a change in scale is the eigenvector, _v_, and the scaling factor is the eigenvalue, _λ_.

That's the essence of eigenvectors and eigenvalues. Notice that we associate these objects with linear map ___B___. Those familiar with German probably recognize that the prefix eigen roughly means "self-" or "unique to" or "peculiar to". Eigenvectors and eigenvalues are tightly coupled to the tensor from which they arise. Indeed, they reveal a significant characteristic of the tensor. Here are some illustrations.